{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# import pandas as pd\n","from matplotlib import pyplot as plt\n","import datetime\n","import seaborn as sns\n","import h5py\n","import warnings\n","from enum import Enum\n","warnings.filterwarnings(\"ignore\")\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.style.use('seaborn')\n","plt.rcParams['figure.figsize'] = (15, 9)\n","plt.rcParams['grid.color'] = '#E0E0E0'\n","plt.rcParams['lines.linewidth'] = 1\n","plt.rcParams['axes.facecolor'] = '#FBFBFB'\n","plt.rcParams[\"axes.edgecolor\"] = '#222222'\n","plt.rcParams[\"axes.linewidth\"] = 0.5\n","plt.rcParams['xtick.color'] = 'black'\n","plt.rcParams['ytick.color'] = 'black'\n","plt.rcParams['figure.subplot.hspace'] = 0.05  # Shrink the horizontal space\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Custom curve colors\n","# Using mountain and lake names for new color palettes\n","rainbow = ['#3366CC', '#0099C6', '#109618', '#FCE030', '#FF9900', '#DC3912']  # (blue, teal, green, yellow, orange, red)\n","everest = ['#3366CC', '#DC4020', '#10AA18', '#0099C6', '#FCE030', '#FF9900', ]  # (blue, red, green, teal, yellow, orange)\n","\n","k2 = (\n","    sns.color_palette('husl', desat=0.8)[4], # blue\n","    sns.color_palette('tab10')[3], # red\n","    sns.color_palette('deep')[2], # green\n","    sns.color_palette('tab10', desat=0.8)[1], # purple\n","    sns.color_palette('deep', desat=0.8)[4], # purple\n","    sns.color_palette('colorblind')[2], # sea green\n","    sns.color_palette('colorblind')[0], # deep blue\n","    sns.color_palette('husl')[0], # light red\n",")\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Define string formatting constants, which work in string format statements\n","DEG_C_ALT = u'\\N{DEGREE SIGN}C'\n","\n","# Define default line color\n","DEFAULT_COLOR = '#4488ee'\n","\n","\n","class FileType(Enum):\n","    unknown = 0\n","    fixed_width = 1\n","    csv = 2\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def round_time(dt: datetime.datetime = None, roundTo=60):\n","    '''\n","    Round a datetime object to any time in seconds\n","\n","    dt : datetime.datetime object\n","    roundTo : Closest number of seconds to round to. Default = 1 minute.\n","    '''\n","    if dt == None:\n","        dt = datetime.datetime.now()\n","    seconds = (dt.replace(tzinfo=None) - dt.min).seconds\n","    rounding = (seconds+roundTo/2) // roundTo * roundTo\n","    return dt + datetime.timedelta(0, rounding-seconds, -dt.microsecond)\n","\n","\n","def day_of_year_to_datetime(year: int, day_of_year_list: list):\n","    '''\n","    Convert a list of day-of-year values to datetime objects\n","\n","    year : int\n","        Start year of the data\n","    day_of_list : list\n","        List of day-of-year values, e.g., from CE-QUAL-W2\n","    '''\n","    day1 = datetime.datetime(year, 1, 1, 0, 0, 0)\n","    datetimes = []\n","    for d in day_of_year_list:\n","        # Compute the difference, subtracting 1 from the day_of_year\n","        dx = day1 + datetime.timedelta(days=(d-1))\n","        # Round the time\n","        dx = round_time(dt=dx, roundTo=60*60)\n","        datetimes.append(dx)\n","    return datetimes\n","\n","\n","def dataframe_to_date_format(year: int, data_frame: pd.DataFrame):\n","    '''\n","    Convert the day-of-year column in a CE-QUAL-W2 data frame\n","    to datetime objects\n","\n","    year : int\n","        Start year of the data\n","    data_frame : pandas.DataFrame object\n","        Data frame to convert\n","    '''\n","    datetimes = day_of_year_to_datetime(year, data_frame.index)\n","    data_frame.index = datetimes\n","    data_frame.index.name = 'Date'\n","    return data_frame\n","\n","\n","def read_npt(infile: str, year: int, data_columns: list[str], skiprows: int = 3):\n","    '''Read CE-QUAL-W2 time series (fixed-width format, *.npt files)'''\n","\n","    ncols_to_read = len(data_columns) + 1  # number of columns to read, including the date/day column\n","    columns_to_read = ['DoY', *data_columns]\n","    return pd.read_fwf(infile, skiprows=skiprows, widths=ncols_to_read*[8], names=columns_to_read, index_col=0)\n","\n","\n","def read_csv(infile: str, year: int, data_columns: list[str], skiprows: int = 3):\n","    '''Read CE-QUAL-W2 time series (CSV format)'''\n","\n","    try:\n","        df = pd.read_csv(infile, skiprows=skiprows, names=data_columns, index_col=0)\n","    except:\n","        # Handle trailing comma, which adds an extra (empty) column\n","        df = pd.read_csv(infile, skiprows=skiprows, names=[*data_columns, 'JUNK'], index_col=0)\n","        df = df.drop(axis=1, labels='JUNK')\n","    return df\n","\n","\n","def read(infile: str, year: int, data_columns: list[str], skiprows: int = 3, file_type: FileType = None):\n","    '''\n","    Read CE-QUAL-W2 time series data (npt and csv formats) and convert the Day of Year (Julian Day) to date-time format\n","\n","    This function automatically detects the file type, if the file is named with *.npt or *.csv extensions. \n","    '''\n","\n","    # If not defined, set the file type using the input filename\n","    if not file_type:\n","        if infile.lower().endswith('.csv'):\n","            file_type = FileType.csv\n","        elif infile.lower().endswith('.npt'):\n","            file_type = FileType.fixed_width\n","        else:\n","            raise Exception('The file type was not specified, and it could not be determined from the filename.')\n","\n","    # Read the data\n","    if file_type == FileType.fixed_width:\n","        df = read_npt(infile, year, data_columns, skiprows=skiprows)\n","    elif file_type == FileType.csv:\n","        df = read_csv(infile, year, data_columns, skiprows=skiprows)\n","    else:\n","        raise Exception('Error: file_type is not defined correctly.')\n","\n","    # Convert day-of-year column of the data frames to date format\n","    df = dataframe_to_date_format(year, df)\n","\n","    return df\n","\n","\n","def read_met(infile: str, year: int, data_columns: list[str] = None, skiprows: int = 3):\n","    '''Read meteorology time series'''\n","    if not data_columns:\n","        data_columns = [\n","            'Air Temperature ($^oC$)',\n","            'Dew Point Temperature ($^oC$)',\n","            'Wind Speed (m/s)',\n","            'Wind Direction (radians)',\n","            'Cloudiness (fraction)',\n","            'Solar Radiation ($W/m^2$)'\n","        ]\n","\n","    return read(infile, year, data_columns, skiprows=skiprows)\n","\n","\n","def get_colors(df: pd.DataFrame, palette: str, min_colors=6):\n","    '''Get list of colors from the specified Seaborn color palette'''\n","\n","    colors = sns.color_palette(palette, min(min_colors, len(df.columns)))\n","    return colors\n","\n","\n","def plot(df, title: str = None, legend_list: list[str] = None,\n","         xlabel: str = None, ylabel: str = None, colors: list[str] = None,\n","         figsize=(15, 9), style: str = '-', palette: str = 'colorblind', **kwargs):\n","    '''Plot all columns in one figure'''\n","\n","    fig, axes = plt.subplots(figsize=figsize)\n","\n","    if not colors:\n","        colors = get_colors(df, palette, min_colors=6)\n","\n","    axes.set_prop_cycle(\"color\", colors)\n","\n","    df.plot(ax=axes, title=title, ylabel=ylabel, style=style)\n","\n","    if legend_list:\n","        axes.legend(legend_list)\n","\n","    fig.tight_layout()  # This resolves a lot of layout issues\n","\n","\n","def multiplot(df, title: str = None, legend_list: list[str] = None, xlabel: str = None,\n","              ylabels: list[str] = None, colors: list[str] = None, figsize=(15, 21),\n","              style: str = '-', palette: str = 'colorblind', **kwargs):\n","    '''Plot each column as a separate subplot'''\n","\n","    fig, axes = plt.subplots(figsize=figsize)\n","    plt.subplots_adjust(top=0.97)  # Save room for the plot title\n","\n","    if not colors:\n","        colors = get_colors(df, palette, min_colors=6)\n","\n","    axes.set_prop_cycle(\"color\", colors)\n","\n","    subplot_axes = df.plot(subplots=True, ax=axes, sharex=True, legend=False, title=title, style=style, color=colors)\n","\n","    if title:\n","        axes.set_title(title)\n","\n","    if not ylabels:\n","        ylabels = df.columns\n","\n","    # Label each sub-plot's y-axis\n","    for ax, ylabel in zip(subplot_axes, ylabels):\n","        ax.set_ylabel(ylabel)\n","\n","    if legend_list:\n","        axes.legend(legend_list)\n","\n","    fig.tight_layout()  # This resolves a lot of layout issues\n","\n","\n","def write_hdf(df: pd.DataFrame, group: str, outfile: str, overwrite=True):\n","    '''\n","    Write CE-QUAL-W2 timeseries dataframe to HDF5\n","\n","    The index column must be a datetime array. This columns will be written to HDF5 as a string array. \n","    Each data column will be written using its data type.\n","    '''\n","\n","    with h5py.File(outfile, 'a') as f:\n","        index = df.index.astype('str')\n","        string_dt = h5py.special_dtype(vlen=str)\n","        date_path = group + '/' + df.index.name\n","        if overwrite and (date_path in f):\n","            del f[date_path]\n","        f.create_dataset(date_path, data=index, dtype=string_dt)\n","\n","        for col in df.columns:\n","            ts_path = group + '/' + col\n","            if overwrite and (ts_path in f):\n","                del f[ts_path]\n","            f.create_dataset(ts_path, data=df[col])\n","\n","\n","def read_hdf(group: str, infile: str, variables: list[str]):\n","    '''\n","    Read CE-QUAL-W2 timeseries dataframe to HDF5\n","\n","    This function assumes that a string-based datetime array named Date is present. This will be read and \n","    assiened as the index column of the output pandas dataframe will be a datetime array. \n","    '''\n","\n","    with h5py.File(infile, 'r') as f:\n","        # Read dates\n","        date_path = group + '/' + 'Date'\n","        dates_str = f.get(date_path)\n","\n","        # Read time series data\n","        ts = {}\n","        for v in variables:\n","            ts_path = group + '/' + v\n","            ts[v] = f.get(ts_path)\n","\n","        dates = []\n","        for dstr in dates_str:\n","            dstr = dstr.decode('utf-8')\n","            d = pd.to_datetime(dstr)\n","            dates.append(d)\n","        \n","        df = pd.DataFrame(ts, index=dates)\n","        return df"]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"orig_nbformat":4}}